{
  "name": "moderator",
  "displayName": "Content Moderator Agent",
  "version": "1.0.0",
  "description": "AI agent specialized in content moderation, safety checking, and policy enforcement using LangGraph workflows",
  "role": "ADMIN",
  "avatar": "https://api.dicebear.com/7.x/bottts/svg?seed=moderator",
  "capabilities": [
    "Content safety analysis",
    "Policy violation detection",
    "Toxicity assessment",
    "Spam detection",
    "Age-appropriate content filtering",
    "Automated reporting"
  ],
  "langGraphSpec": {
    "workflow": "moderation_workflow",
    "nodes": [
      {
        "id": "content_classifier",
        "type": "agent",
        "description": "Classifies content type and extracts features"
      },
      {
        "id": "toxicity_detector",
        "type": "agent",
        "description": "Detects toxic, harmful, or inappropriate content"
      },
      {
        "id": "policy_checker",
        "type": "agent",
        "description": "Checks content against platform policies"
      },
      {
        "id": "spam_detector",
        "type": "agent",
        "description": "Identifies spam and promotional content"
      },
      {
        "id": "age_verifier",
        "type": "agent",
        "description": "Verifies age-appropriateness of content"
      },
      {
        "id": "action_determiner",
        "type": "agent",
        "description": "Determines moderation action based on analysis"
      }
    ],
    "edges": [
      {"from": "content_classifier", "to": "toxicity_detector"},
      {"from": "content_classifier", "to": "spam_detector"},
      {"from": "content_classifier", "to": "age_verifier"},
      {"from": "toxicity_detector", "to": "policy_checker"},
      {"from": "spam_detector", "to": "policy_checker"},
      {"from": "age_verifier", "to": "policy_checker"},
      {"from": "policy_checker", "to": "action_determiner"}
    ],
    "conditionalEdges": [
      {
        "from": "action_determiner",
        "condition": "needs_human_review",
        "to": "human_escalation"
      }
    ]
  },
  "tools": [
    "text_classifier",
    "image_analyzer",
    "sentiment_analyzer",
    "language_detector",
    "profanity_filter",
    "policy_engine",
    "reporting_system"
  ],
  "configuration": {
    "toxicity_threshold": 0.8,
    "spam_threshold": 0.7,
    "supported_languages": ["en", "es", "fr", "de", "pt"],
    "escalation_rules": {
      "high_risk": "immediate_review",
      "medium_risk": "queue_review",
      "low_risk": "auto_approve"
    }
  },
  "implementation": "TODO: Implement LangGraph workflow for content moderator agent"
} 